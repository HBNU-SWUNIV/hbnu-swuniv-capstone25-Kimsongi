# 한밭대학교 컴퓨터공학과 김송이팀

**팀 구성**
- 20221999 이경림 
- 20191770 김하현
- 20222028 송채린

## <u>Teamate</u> Project Background
- ### 필요성
<img width="942" height="208" alt="image" src="https://github.com/user-attachments/assets/2c9bd55e-fba2-45ad-b6b6-ff8f9bdf966d" />

  - 연구 부족 + 각 국가별 다양한 수어 존재 → 실시간 다국어 수어 번역 애플리케이션 부재
- ### 기존 해결책의 문제점
    1. 수어 번역의 정확도 문제 : 문장 단위 번역이 아닌 단어 단위 번역에 초점
    2. 다양한 환경에서의 인식 어려움 : 실제 사용 환경에서는 번역 정확도 하락
  
## System Design
  - ### System Requirements
    - Python 3.10
    - Git LFS (대용량 모델 파일(.h5, .safetensors) 다운로드)
    - TensorFlow & Keras (LSTM 단어 인식 모델 실행)
    - PyTorch (T5 문장 생성 모델 실행)
    - Transformers (T5 모델 로드 및 토크나이저)
    - OpenCV (실시간 카메라 영상 처리)
    - Mediapipe (실시간 손 관절 좌표 추출)
    - Scikit-learn (데이터 전처리 및 LabelEncoder)
    - CUDA 11.x (NVIDIA GPU 가속을 위해 권장)
    
## Case Study
  - ### 기존 관련 특허들의 실제 한계 분석

  | 특허명 (출원번호/출원인) | 핵심 기술 구조 | 한계점 |
  |---------------------------|----------------|--------|
  | 스마트 수어 인식 장치 (10-2020-0101234 / 삼성전자) | IMU로 손가락 각도·자세 인식 후 텍스트 변환 | 단어 수준 인식에 한정, 문장 생성형 AI 부재 |
  | EMG 기반 수어 번역 장치 (10-2021-0045123 / ETRI) | EMG(근전도) 신호로 손동작 분류 | EMG 단독으로 표현 범위 제한, 문맥 이해 불가 |
  | 모바일 수어 통역 시스템 (10-2022-0098765 / KAIST) | 카메라 기반 Mediapipe/CNN-LSTM 영상 인식 | 영상 단어 인식까지만, T5·GPT류 문장 생성 미통합 |
  | 실시간 수어 번역 애플리케이션 (WO2023/087654 / Google LLC) | Transformer로 단어 변환 및 텍스트 출력 | 실시간 구조는 있으나 모듈별 AI 병렬 처리·문장 생성 없음 |
  
## Conclusion
  - ### 
    1. 본 아이디어는 Mediapipe 기반 손동작 인식 + LSTM 단어 인식 + T5 문장 생성 + 번역 API를 통합하여 문맥 단위 실시간 번역을 구현
    2. 별도 하드웨어 없이 스마트폰 카메라만으로 동작하는 점에서 접근성 측면의 신규성 확보
  - ### OOO
    1. 단순한 센서/모델의 나열이 아니라, 단어→문장 생성→번역으로 이어지는 모델 간 상호작용 파이프라인으로 품질을 고도화
    2. 무료 모바일 앱으로 제공되어 사회적 확장성 동반
  
## Project Outcome
- ### 
